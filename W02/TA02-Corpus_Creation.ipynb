{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dogs_dict = { 'Ozzy': 3, 'Filou': 8, 'Luna': 5, 'Skippy': 10, 'Barco': 12, 'Balou': 9, 'Laika': 16 }\n",
    "filename = 'dogs'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(dogs_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ozzy': 3, 'Filou': 8, 'Luna': 5, 'Skippy': 10, 'Barco': 12, 'Balou': 9, 'Laika': 16}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(filename,'rb') as f:\n",
    "    new_dict = pickle.load(f)\n",
    "print(new_dict)\n",
    "print(type(new_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x000001A494108720>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m p \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mPool(\u001b[39m2\u001b[39m) \u001b[39m#Pool specifies number of processes to run\u001b[39;00m\n\u001b[0;32m      4\u001b[0m p\u001b[39m.\u001b[39mmap(cos,\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m result_power \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mx, \u001b[39mrange\u001b[39;49m(\u001b[39m10\u001b[39;49m))\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(result_power)\n",
      "File \u001b[1;32mc:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:540\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[1;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     put(task)\n\u001b[0;32m    541\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    542\u001b[0m     job, idx \u001b[39m=\u001b[39m task[:\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:205\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_writable()\n\u001b[1;32m--> 205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_bytes(_ForkingPickler\u001b[39m.\u001b[39;49mdumps(obj))\n",
      "File \u001b[1;32mc:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[1;34m(cls, obj, protocol)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdumps\u001b[39m(\u001b[39mcls\u001b[39m, obj, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     50\u001b[0m     buf \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mcls\u001b[39;49m(buf, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m buf\u001b[39m.\u001b[39mgetbuffer()\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000001A494108720>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from math import cos\n",
    "p = mp.Pool(2) #Pool specifies number of processes to run\n",
    "p.map(cos,range(10))\n",
    "result_power = p.map(lambda x: 2**x, range(10))\n",
    "print(result_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter data using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "                                              0.0/98.5 kB ? eta -:--:--\n",
      "     ---------------                        41.0/98.5 kB 991.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 98.5/98.5 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "                                              0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.27.0 (from tweepy)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "                                              0.0/62.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 62.6/62.6 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib<2,>=1.2.0 (from tweepy)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27.0->tweepy)\n",
      "  Downloading charset_normalizer-3.2.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "                                              0.0/96.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.6/96.6 kB ? eta 0:00:00\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.27.0->tweepy)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "                                              0.0/61.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.5/61.5 kB ? eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27.0->tweepy)\n",
      "  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "                                              0.0/123.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 123.9/123.9 kB ? eta 0:00:00\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.27.0->tweepy)\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "                                              0.0/158.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 158.3/158.3 kB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, oauthlib, idna, charset-normalizer, certifi, requests, requests-oauthlib, tweepy\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 idna-3.4 oauthlib-3.2.2 requests-2.31.0 requests-oauthlib-1.3.1 tweepy-4.14.0 urllib3-2.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'YOUR-CONSUMER-KEY'\n",
    "consumer_secret = 'YOUR-CONSUMER-SECRET'\n",
    "access_token = 'YOUR-ACCESS-TOKEN'\n",
    "access_secret = 'YOUR-ACCESS-SECRET'\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "for tweets in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    print(tweet.user.screen_name, tweet.created_at, tweet.text)\n",
    "with open('C:/Users/abhatt/Desktop/python/Tweets.json', 'a') as f:\n",
    "    for tweet in tweepy.Cursor(api.home_timeline).items(10):\n",
    "        json.dump(tweet._json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.plaintext.PlaintextCorpusReader"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()\n",
    "type(gutenberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'\", 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'Her']\n"
     ]
    }
   ],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')\n",
    "len(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 24 26 austen-emma.txt\n",
      "4 26 16 austen-persuasion.txt\n",
      "4 28 22 austen-sense.txt\n",
      "4 33 79 bible-kjv.txt\n",
      "4 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 17 12 burgess-busterbrown.txt\n",
      "4 20 12 carroll-alice.txt\n",
      "4 20 11 chesterton-ball.txt\n",
      "4 22 11 chesterton-brown.txt\n",
      "4 18 10 chesterton-thursday.txt\n",
      "4 20 24 edgeworth-parents.txt\n",
      "4 25 15 melville-moby_dick.txt\n",
      "4 52 10 milton-paradise.txt\n",
      "4 11 8 shakespeare-caesar.txt\n",
      "4 12 7 shakespeare-hamlet.txt\n",
      "4 12 6 shakespeare-macbeth.txt\n",
      "4 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))\n",
    "    print(int(num_chars/num_words), int(num_words/num_sents),\n",
    "    int(num_words/num_vocab), fileid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
