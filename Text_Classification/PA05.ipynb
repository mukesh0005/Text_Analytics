{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Tweets: Sentiment Analysis & Simple Classification\n",
    "\n",
    "### ISM6564\n",
    "\n",
    "**Week05\n",
    "\n",
    "&copy; 2023 Dr. Tim Smith\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we will analysze the sentiment from a dataset on how travelers tweeted about their airline-related feelings, scraped from Twitter in February 2015;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import tools to pre-process the text data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Extracting features from text files\n",
    "#   SciKit Learn includes a number of useful feature extraction classes \n",
    "#   https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "# \n",
    "#   We will use TfidfVectorizer (which includes pre-processing, tokenization, and filtering out stop words)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import tools to reduce the dimensionality of the data\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# import tools to split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import ML classifiers we will use to model the data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# import tools to evaluate the model performance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dsata Load and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data \n",
    "df = pd.read_csv('./data/A_tweets.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def clear_text(text):\n",
    "    # tokenize the text\n",
    "    # nltk.download('punkt') # uncomment if you need to download the punkt package\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # remove all tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # make lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # remove all tokens that are only one character\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_text']=df.text.apply(lambda x: clear_text(x))   \n",
    "df['hashtags'] = df.text.apply(lambda text: re.findall(r\"#(\\w+)\", text))\n",
    "df['handles'] = df.text.apply(lambda text: re.findall(r\"@(\\w+)\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>handles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>what said</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica, dhepburn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>plus added commercials to the experience tacky</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>today must mean need to take another trip</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>really aggressive to blast obnoxious entertain...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>and really big bad thing about it</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>seriously would pay flight for seats that have...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>570300616901320704</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:13:57 -0800</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>yes nearly every time fly vx this ear worm won...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>570300248553349120</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pilot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:12:29 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>really missed prime opportunity for men withou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>570299953286942721</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dhepburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:11:19 -0800</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>well but now do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[virginamerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YupitsTate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:53:27 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>it was amazing and arrived an hour early too g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "5  570300767074181121          negative                        1.0000   \n",
       "6  570300616901320704          positive                        0.6745   \n",
       "7  570300248553349120           neutral                        0.6340   \n",
       "8  570299953286942721          positive                        0.6559   \n",
       "9  570295459631263746          positive                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "5     Can't Tell                     0.6842  Virgin America   \n",
       "6            NaN                     0.0000  Virgin America   \n",
       "7            NaN                        NaN  Virgin America   \n",
       "8            NaN                        NaN  Virgin America   \n",
       "9            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "5                    NaN    jnardino                 NaN              0   \n",
       "6                    NaN  cjmcginnis                 NaN              0   \n",
       "7                    NaN       pilot                 NaN              0   \n",
       "8                    NaN    dhepburn                 NaN              0   \n",
       "9                    NaN  YupitsTate                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
       "7  @VirginAmerica Really missed a prime opportuni...         NaN   \n",
       "8    @virginamerica Well, I didn't…but NOW I DO! :-D         NaN   \n",
       "9  @VirginAmerica it was amazing, and arrived an ...         NaN   \n",
       "\n",
       "               tweet_created    tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800               NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800               NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)   \n",
       "3  2015-02-24 11:15:36 -0800               NaN  Pacific Time (US & Canada)   \n",
       "4  2015-02-24 11:14:45 -0800               NaN  Pacific Time (US & Canada)   \n",
       "5  2015-02-24 11:14:33 -0800               NaN  Pacific Time (US & Canada)   \n",
       "6  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)   \n",
       "7  2015-02-24 11:12:29 -0800       Los Angeles  Pacific Time (US & Canada)   \n",
       "8  2015-02-24 11:11:19 -0800         San Diego  Pacific Time (US & Canada)   \n",
       "9  2015-02-24 10:53:27 -0800       Los Angeles  Eastern Time (US & Canada)   \n",
       "\n",
       "                                          clean_text hashtags  \\\n",
       "0                                          what said       []   \n",
       "1     plus added commercials to the experience tacky       []   \n",
       "2          today must mean need to take another trip       []   \n",
       "3  really aggressive to blast obnoxious entertain...       []   \n",
       "4                  and really big bad thing about it       []   \n",
       "5  seriously would pay flight for seats that have...       []   \n",
       "6  yes nearly every time fly vx this ear worm won...       []   \n",
       "7  really missed prime opportunity for men withou...       []   \n",
       "8                                    well but now do       []   \n",
       "9  it was amazing and arrived an hour early too g...       []   \n",
       "\n",
       "                     handles  \n",
       "0  [VirginAmerica, dhepburn]  \n",
       "1            [VirginAmerica]  \n",
       "2            [VirginAmerica]  \n",
       "3            [VirginAmerica]  \n",
       "4            [VirginAmerica]  \n",
       "5            [VirginAmerica]  \n",
       "6            [VirginAmerica]  \n",
       "7            [VirginAmerica]  \n",
       "8            [virginamerica]  \n",
       "9            [VirginAmerica]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['clean_text', 'airline', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text           0\n",
       "airline              0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Virgin America', 'United', 'Southwest', 'Delta', 'US Airways',\n",
       "       'American'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what said</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus added commercials to the experience tacky</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today must mean need to take another trip</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive to blast obnoxious entertain...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay flight for seats that have...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes nearly every time fly vx this ear worm won...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed prime opportunity for men withou...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well but now do</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing and arrived an hour early too g...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text airline_sentiment  \\\n",
       "0                                          what said           neutral   \n",
       "1     plus added commercials to the experience tacky          positive   \n",
       "2          today must mean need to take another trip           neutral   \n",
       "3  really aggressive to blast obnoxious entertain...          negative   \n",
       "4                  and really big bad thing about it          negative   \n",
       "5  seriously would pay flight for seats that have...          negative   \n",
       "6  yes nearly every time fly vx this ear worm won...          positive   \n",
       "7  really missed prime opportunity for men withou...           neutral   \n",
       "8                                    well but now do          positive   \n",
       "9  it was amazing and arrived an hour early too g...          positive   \n",
       "\n",
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 0              0                  0                   0   \n",
       "1                 0              0                  0                   0   \n",
       "2                 0              0                  0                   0   \n",
       "3                 0              0                  0                   0   \n",
       "4                 0              0                  0                   0   \n",
       "5                 0              0                  0                   0   \n",
       "6                 0              0                  0                   0   \n",
       "7                 0              0                  0                   0   \n",
       "8                 0              0                  0                   0   \n",
       "9                 0              0                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America  \n",
       "0               0                       1  \n",
       "1               0                       1  \n",
       "2               0                       1  \n",
       "3               0                       1  \n",
       "4               0                       1  \n",
       "5               0                       1  \n",
       "6               0                       1  \n",
       "7               0                       1  \n",
       "8               0                       1  \n",
       "9               0                       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(\n",
    "    df, \n",
    "    prefix_sep='_', \n",
    "    dummy_na=False, \n",
    "    drop_first=False, \n",
    "    columns=['airline'], \n",
    "    dtype='int32'\n",
    ")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what said</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus added commercials to the experience tacky</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today must mean need to take another trip</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive to blast obnoxious entertain...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and really big bad thing about it</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay flight for seats that have...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes nearly every time fly vx this ear worm won...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed prime opportunity for men withou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well but now do</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing and arrived an hour early too g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  airline_sentiment  \\\n",
       "0                                          what said                  0   \n",
       "1     plus added commercials to the experience tacky                  1   \n",
       "2          today must mean need to take another trip                  0   \n",
       "3  really aggressive to blast obnoxious entertain...                 -1   \n",
       "4                  and really big bad thing about it                 -1   \n",
       "5  seriously would pay flight for seats that have...                 -1   \n",
       "6  yes nearly every time fly vx this ear worm won...                  1   \n",
       "7  really missed prime opportunity for men withou...                  0   \n",
       "8                                    well but now do                  1   \n",
       "9  it was amazing and arrived an hour early too g...                  1   \n",
       "\n",
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 0              0                  0                   0   \n",
       "1                 0              0                  0                   0   \n",
       "2                 0              0                  0                   0   \n",
       "3                 0              0                  0                   0   \n",
       "4                 0              0                  0                   0   \n",
       "5                 0              0                  0                   0   \n",
       "6                 0              0                  0                   0   \n",
       "7                 0              0                  0                   0   \n",
       "8                 0              0                  0                   0   \n",
       "9                 0              0                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America  \n",
       "0               0                       1  \n",
       "1               0                       1  \n",
       "2               0                       1  \n",
       "3               0                       1  \n",
       "4               0                       1  \n",
       "5               0                       1  \n",
       "6               0                       1  \n",
       "7               0                       1  \n",
       "8               0                       1  \n",
       "9               0                       1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'] = df['airline_sentiment'].apply(lambda x: -1 if x.lower() == 'negative' else (1 if x.lower() == 'positive' else 0))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['airline_sentiment'], axis=1)  \n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10248, 7), (4392, 7), (10248,), (4392,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(clean_text                0\n",
       " airline_American          0\n",
       " airline_Delta             0\n",
       " airline_Southwest         0\n",
       " airline_US Airways        0\n",
       " airline_United            0\n",
       " airline_Virgin America    0\n",
       " dtype: int64,\n",
       " clean_text                0\n",
       " airline_American          0\n",
       " airline_Delta             0\n",
       " airline_Southwest         0\n",
       " airline_US Airways        0\n",
       " airline_United            0\n",
       " airline_Virgin America    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum(), X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11077</th>\n",
       "      <td>thanks made it safely</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>am now rapids rewards member</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>would like your baggage damage number as well ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11690</th>\n",
       "      <td>yes can pay out of pocket that us not helping ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>with karen and found her unhelpful and rude ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>think need selfie as proof</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>trying to book flight with you guys and your w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>after several trials and several hours of wait...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>looks like on february we will open our schedu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>raise dispute with your cc provider and they w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  airline_American  \\\n",
       "11077                              thanks made it safely                 0   \n",
       "6051                        am now rapids rewards member                 0   \n",
       "1929   would like your baggage damage number as well ...                 0   \n",
       "11690  yes can pay out of pocket that us not helping ...                 0   \n",
       "4236   with karen and found her unhelpful and rude ca...                 0   \n",
       "8682                          think need selfie as proof                 0   \n",
       "191    trying to book flight with you guys and your w...                 0   \n",
       "2881   after several trials and several hours of wait...                 0   \n",
       "6104   looks like on february we will open our schedu...                 0   \n",
       "3776   raise dispute with your cc provider and they w...                 0   \n",
       "\n",
       "       airline_Delta  airline_Southwest  airline_US Airways  airline_United  \\\n",
       "11077              0                  0                   1               0   \n",
       "6051               0                  1                   0               0   \n",
       "1929               0                  0                   0               1   \n",
       "11690              0                  0                   1               0   \n",
       "4236               0                  0                   0               1   \n",
       "8682               1                  0                   0               0   \n",
       "191                0                  0                   0               0   \n",
       "2881               0                  0                   0               1   \n",
       "6104               0                  1                   0               0   \n",
       "3776               0                  0                   0               1   \n",
       "\n",
       "       airline_Virgin America  \n",
       "11077                       0  \n",
       "6051                        0  \n",
       "1929                        0  \n",
       "11690                       0  \n",
       "4236                        0  \n",
       "8682                        0  \n",
       "191                         1  \n",
       "2881                        0  \n",
       "6104                        0  \n",
       "3776                        0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa            0\n",
      "aaaand        0\n",
      "aadv          0\n",
      "aadvantage    0\n",
      "aaron         0\n",
      "             ..\n",
      "zone          0\n",
      "zones         0\n",
      "zoom          0\n",
      "zukes         0\n",
      "zurich        0\n",
      "Length: 8194, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abassinet</th>\n",
       "      <th>abbreve</th>\n",
       "      <th>...</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippers</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaand  aadv  aadvantage  aaron   ab  aback  abandonment  abassinet  \\\n",
       "0  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "1  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "2  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "3  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "4  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "5  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "6  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "7  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "8  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "9  0.0     0.0   0.0         0.0    0.0  0.0    0.0          0.0        0.0   \n",
       "\n",
       "   abbreve  ...  zabsonre  zcc  zero  zip  zippers  zone  zones  zoom  zukes  \\\n",
       "0      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "1      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "2      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "3      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "4      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "5      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "6      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "7      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "8      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "9      0.0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0   \n",
       "\n",
       "   zurich  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "6     0.0  \n",
       "7     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "\n",
       "[10 rows x 8194 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(X_train['clean_text'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(tfidf_df.isna().sum())\n",
    "\n",
    "tfidf_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10248, 7), (10248, 8194))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text            0\n",
       "airline_American      0\n",
       "airline_Delta         0\n",
       "airline_Southwest     0\n",
       "airline_US Airways    0\n",
       "                     ..\n",
       "zone                  0\n",
       "zones                 0\n",
       "zoom                  0\n",
       "zukes                 0\n",
       "zurich                0\n",
       "Length: 8201, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop=True) # need to do this, since X_train and tfidf_df have different indices\n",
    "\n",
    "X_train = pd.concat([X_train, tfidf_df], axis=1)\n",
    "\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>...</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippers</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 0              0                  0                   1   \n",
       "1                 0              0                  1                   0   \n",
       "2                 0              0                  0                   0   \n",
       "3                 0              0                  0                   1   \n",
       "4                 0              0                  0                   0   \n",
       "5                 0              1                  0                   0   \n",
       "6                 0              0                  0                   0   \n",
       "7                 0              0                  0                   0   \n",
       "8                 0              0                  1                   0   \n",
       "9                 0              0                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America   aa  aaaand  aadv  aadvantage  ...  \\\n",
       "0               0                       0  0.0     0.0   0.0         0.0  ...   \n",
       "1               0                       0  0.0     0.0   0.0         0.0  ...   \n",
       "2               1                       0  0.0     0.0   0.0         0.0  ...   \n",
       "3               0                       0  0.0     0.0   0.0         0.0  ...   \n",
       "4               1                       0  0.0     0.0   0.0         0.0  ...   \n",
       "5               0                       0  0.0     0.0   0.0         0.0  ...   \n",
       "6               0                       1  0.0     0.0   0.0         0.0  ...   \n",
       "7               1                       0  0.0     0.0   0.0         0.0  ...   \n",
       "8               0                       0  0.0     0.0   0.0         0.0  ...   \n",
       "9               1                       0  0.0     0.0   0.0         0.0  ...   \n",
       "\n",
       "   zabsonre  zcc  zero  zip  zippers  zone  zones  zoom  zukes  zurich  \n",
       "0       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "1       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "2       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "3       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "4       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "5       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "6       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "7       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "8       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "9       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "\n",
       "[10 rows x 8200 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop('clean_text',axis=1)\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_American      0\n",
       "airline_Delta         0\n",
       "airline_Southwest     0\n",
       "airline_US Airways    0\n",
       "airline_United        0\n",
       "                     ..\n",
       "zone                  0\n",
       "zones                 0\n",
       "zoom                  0\n",
       "zukes                 0\n",
       "zurich                0\n",
       "Length: 8200, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>...</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippers</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 1              0                  0                   0   \n",
       "1                 0              1                  0                   0   \n",
       "2                 1              0                  0                   0   \n",
       "3                 1              0                  0                   0   \n",
       "4                 0              0                  0                   0   \n",
       "5                 0              0                  0                   1   \n",
       "6                 0              0                  1                   0   \n",
       "7                 0              0                  0                   1   \n",
       "8                 0              1                  0                   0   \n",
       "9                 1              0                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America        aa  aaaand  aadv  aadvantage  \\\n",
       "0               0                       0  0.000000     0.0   0.0         0.0   \n",
       "1               0                       0  0.000000     0.0   0.0         0.0   \n",
       "2               0                       0  0.000000     0.0   0.0         0.0   \n",
       "3               0                       0  0.256364     0.0   0.0         0.0   \n",
       "4               1                       0  0.000000     0.0   0.0         0.0   \n",
       "5               0                       0  0.000000     0.0   0.0         0.0   \n",
       "6               0                       0  0.000000     0.0   0.0         0.0   \n",
       "7               0                       0  0.000000     0.0   0.0         0.0   \n",
       "8               0                       0  0.000000     0.0   0.0         0.0   \n",
       "9               0                       0  0.000000     0.0   0.0         0.0   \n",
       "\n",
       "   ...  zabsonre  zcc  zero  zip  zippers  zone  zones  zoom  zukes  zurich  \n",
       "0  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "1  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "2  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "3  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "4  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "5  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "6  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "7  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "8  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "9  ...       0.0  0.0   0.0  0.0      0.0   0.0    0.0   0.0    0.0     0.0  \n",
       "\n",
       "[10 rows x 8200 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = vectorizer.transform(X_test['clean_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "X_test = X_test.reset_index(drop=True) # need to do this, since X_train and tfidf_df have different indices\n",
    "X_test = pd.concat([X_test, tfidf_df], axis=1)\n",
    "X_test = X_test.drop('clean_text',axis=1)\n",
    "\n",
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_American      0\n",
       "airline_Delta         0\n",
       "airline_Southwest     0\n",
       "airline_US Airways    0\n",
       "airline_United        0\n",
       "                     ..\n",
       "zone                  0\n",
       "zones                 0\n",
       "zoom                  0\n",
       "zukes                 0\n",
       "zurich                0\n",
       "Length: 8200, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4392, 8200), (10248, 8200))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Reduced Dimensions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User singular value decomposition (SVD) to create a reduced dimension dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500, n_iter=10) #n_components is the number of topics, which should be less than the number of features, and number of rows in the matrix\n",
    "\n",
    "X_train_dim_reduct = svd.fit_transform(X_train)\n",
    "X_test_dim_reduct = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10248, 500), (4392, 500))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dim_reduct.shape, X_test_dim_reduct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit RandomForrestClassifier using the dimension reduced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15min 24s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=50, n_jobs=-1).fit(X_train_dim_reduct, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred = rf_clf.predict(X_test_dim_reduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6775\n",
      "Test accuracy: 0.6644\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2745,   14,    0],\n",
       "       [ 806,   94,    6],\n",
       "       [ 619,   29,   79]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_, colorbar=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred, display_labels=[-1,0,1], ax=ax, colorbar=False, cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.87037</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Accuracy  Precision    Recall        F1\n",
       "0  Random Forest dim reduced  0.775895    0.87037  0.104444  0.186508"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest dim reduced\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RandomForrestClassifier using the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 10s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=50, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train)\n",
    "y_test_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6581\n",
      "Test accuracy: 0.6582\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2752,    7,    0],\n",
       "       [ 855,   45,    6],\n",
       "       [ 628,    5,   94]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_, colorbar=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred, display_labels=[-1,0,1], ax=ax, colorbar=False, cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.764417</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Accuracy  Precision    Recall        F1\n",
       "0  Random Forest dim reduced  0.775895   0.870370  0.104444  0.186508\n",
       "0              Random Forest  0.764417   0.865385  0.050000  0.094538"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RandomForrestClassifier using the dimension reduced training data and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop =30, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [len(X_train.columns), len(X_train.columns)//2, len(X_train.columns)//5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 20, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf, \n",
    "    param_distributions = random_grid, \n",
    "    n_iter = 10, \n",
    "    cv = 3, \n",
    "    verbose=1, \n",
    "    random_state=42, \n",
    "    n_jobs = -1)\n",
    "\n",
    "_ = rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 21,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 1640,\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf_random.best_estimator_.predict(X_train)\n",
    "y_test_pred = rf_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9859\n",
      "Test accuracy: 0.7436\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2491,  173,   95],\n",
       "       [ 444,  384,   78],\n",
       "       [ 212,  124,  391]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_, colorbar=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred, display_labels=[-1,0,1], ax=ax, colorbar=False, cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.764417</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Random Search</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.554513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy  Precision    Recall        F1\n",
       "0    Random Forest dim reduced  0.775895   0.870370  0.104444  0.186508\n",
       "0                Random Forest  0.764417   0.865385  0.050000  0.094538\n",
       "0  Random Forest Random Search  0.823310   0.689408  0.463768  0.554513"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest Random Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none',max_iter=2000)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train,order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.764417</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Random Search</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.554513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.784726</td>\n",
       "      <td>0.537129</td>\n",
       "      <td>0.559278</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy  Precision    Recall        F1\n",
       "0    Random Forest dim reduced  0.775895   0.870370  0.104444  0.186508\n",
       "0                Random Forest  0.764417   0.865385  0.050000  0.094538\n",
       "0  Random Forest Random Search  0.823310   0.689408  0.463768  0.554513\n",
       "0             default logistic  0.784726   0.537129  0.559278  0.547980"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop =50, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [len(X_train.columns), len(X_train.columns)//2, len(X_train.columns)//5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "lg = LogisticRegression()\n",
    "lg_random = RandomizedSearchCV(\n",
    "    estimator = rf, \n",
    "    param_distributions = random_grid, \n",
    "    n_iter = 10, \n",
    "    cv = 3, \n",
    "    verbose=1, \n",
    "    random_state=42, \n",
    "    n_jobs = -1)\n",
    "\n",
    "_ = lg_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.764417</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Random Search</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.554513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.784726</td>\n",
       "      <td>0.537129</td>\n",
       "      <td>0.559278</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_logistic</td>\n",
       "      <td>0.817950</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.395266</td>\n",
       "      <td>0.509535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy  Precision    Recall        F1\n",
       "0    Random Forest dim reduced  0.775895   0.870370  0.104444  0.186508\n",
       "0                Random Forest  0.764417   0.865385  0.050000  0.094538\n",
       "0  Random Forest Random Search  0.823310   0.689408  0.463768  0.554513\n",
       "0             default logistic  0.784726   0.537129  0.559278  0.547980\n",
       "0         rand_search_logistic  0.817950   0.716738  0.395266  0.509535"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = lg_random.best_estimator_.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"rand_search_logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic with dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none',max_iter=2000)\n",
    "_ = log_reg_model.fit(X_train_dim_reduct, np.ravel(y_train,order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.764417</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Random Search</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.554513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.784726</td>\n",
       "      <td>0.537129</td>\n",
       "      <td>0.559278</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_logistic</td>\n",
       "      <td>0.817950</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.395266</td>\n",
       "      <td>0.509535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic dimension reduction</td>\n",
       "      <td>0.847079</td>\n",
       "      <td>0.706553</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.650066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0     Random Forest dim reduced  0.775895   0.870370  0.104444  0.186508\n",
       "0                 Random Forest  0.764417   0.865385  0.050000  0.094538\n",
       "0   Random Forest Random Search  0.823310   0.689408  0.463768  0.554513\n",
       "0              default logistic  0.784726   0.537129  0.559278  0.547980\n",
       "0          rand_search_logistic  0.817950   0.716738  0.395266  0.509535\n",
       "0  logistic dimension reduction  0.847079   0.706553  0.601942  0.650066"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test_dim_reduct)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic dimension reduction\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.764417</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest dim reduced</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.186508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.784726</td>\n",
       "      <td>0.537129</td>\n",
       "      <td>0.559278</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_logistic</td>\n",
       "      <td>0.817950</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.395266</td>\n",
       "      <td>0.509535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Random Search</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.554513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic dimension reduction</td>\n",
       "      <td>0.847079</td>\n",
       "      <td>0.706553</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.650066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0                 Random Forest  0.764417   0.865385  0.050000  0.094538\n",
       "0     Random Forest dim reduced  0.775895   0.870370  0.104444  0.186508\n",
       "0              default logistic  0.784726   0.537129  0.559278  0.547980\n",
       "0          rand_search_logistic  0.817950   0.716738  0.395266  0.509535\n",
       "0   Random Forest Random Search  0.823310   0.689408  0.463768  0.554513\n",
       "0  logistic dimension reduction  0.847079   0.706553  0.601942  0.650066"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary:\n",
    "\n",
    "\n",
    "As we can see from performance data frame arranged in descending order of accuracy logistic model with dimension reduction using svd is performing better than most of the models. Even with Random search in Random forest the base model of logistic is performing better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
